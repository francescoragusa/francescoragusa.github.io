<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <title>Francesco Ragusa</title>
        <meta content="width=device-width, initial-scale=1.0" name="viewport">
        <meta content="Free Website Template" name="keywords">
        <meta content="Free Website Template" name="description">

        <!-- Favicon -->
        <link href="img/favicon.ico" rel="icon">

        <!-- Google Fonts -->
        <link rel="preconnect" href="https://fonts.gstatic.com">
        <link href="https://fonts.googleapis.com/css2?family=Averia+Serif+Libre:wght@400;700&family=Poppins&display=swap" rel="stylesheet"> 

        <!-- Font Awesome -->
        <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.10.0/css/all.min.css" rel="stylesheet">

        <!-- Libraries Stylesheet -->
        <link href="lib/owlcarousel/assets/owl.carousel.min.css" rel="stylesheet">
        <link href="lib/lightbox/css/lightbox.min.css" rel="stylesheet">

        <!-- Customized Bootstrap Stylesheet -->
        <link href="css/style.css" rel="stylesheet">
    </head>

    <body data-spy="scroll" data-target=".navbar" data-offset="51">
        <div class="wrapper">
            <div class="sidebar">
                <div class="sidebar-text d-flex flex-column h-100 justify-content-center text-center">
                    <img class="w-100 img-fluid mb-4" src="img/profile.png" alt="Image">
                    <h1 class="mt-2">Francesco Ragusa</h1>
                    <div class="mb-4" style="height: 22px;">
                        <h4 class="typed-text-output d-inline-block text-body"></h4>
                        <div class="typed-text d-none">Research Fellow at University of Catania, Founder and CEO of Next Vision</div>
                    </div>
                    <br>
                    <div class="d-flex justify-content-center mt-auto mb-3">
                        <a class="mx-2" href="#"><i class="fab fa-twitter"></i></a>
                        <a class="mx-2" href="#"><i class="fab fa-linkedin-in"></i></a>
                        <a class="mx-2" href="#"><i class="fab fa-scholar"></i></a>
                    </div>
                    francesco.ragusa@unict.it
                    fragusa@nextvisionlab.it
                    
                </div>
                <div class="sidebar-icon d-flex flex-column h-100 justify-content-center text-right">
                    <i class="fas fa-2x fa-angle-double-right text-primary"></i>
                </div>
            </div>
            <div>
            <div class="content">
                <nav> 
                    <a href="index.html#Research">Research</a> |
                    <a href="index.html">Publications</a> |
                    <a href="talks.html">Talks</a> |
                    <a href="index.html">Teaching</a> |
                    <a href="index.html">Contact</a>
                  </nav>
                </div>
            <div class="content">
                
                <!-- About Start -->
                <div class="container bg-white py-5">
                    <div class="row px-3">
                        <div class="post" id="top">
                            <h1 class="title">
                                Egocentric Vision: Emerging Trends and Human-Centric Applications
                            </h1>
                            <div>
                            <style>
                              
                              table {
                                  width: 100%;
                              }
                              td {
                                  
                                  padding-right:5px;
                                  padding-left:5px;
                              }
                              tr:nth-child(even) {background: #EEE}
                          </style>
                          <p><strong>Tutorial at ICIAP 2025 - 23rd International Conference on Image Analysis and Processing</strong></p>
                          <p><strong> September 15 2025</strong></p>
                          <p>[<a href="#program">Program &amp; Slides</a>][<a href="#reading">Further Reading</a>]</p>
                          <h2 id="tutorial-description">Tutorial Description</h2>
                          <h3 id="abstract">Abstract</h3>
                          <p align="justify">Wearable devices with integrated cameras and computing capabilities are gaining significant attention. With the increasing availability of commercial devices and new product announcements, interest is on the rise. The main attraction of wearable devices lies in their mobility and ability to facilitate user-machine interaction through Augmented Reality. These features make them ideal for developing intelligent assistants that enhance human abilities, with AI and Computer Vision playing crucial roles.</p>
                          <p align="justify">Unlike traditional "third-person vision," which analyzes images from a static viewpoint, first-person (egocentric) vision captures images from the user's perspective, providing unique insights into their activities and interactions. Visual data from wearable cameras offers valuable information about users, their intentions, and their environment.</p>
                          <p align="justify">This tutorial will explore the challenges and opportunities of first-person (egocentric) vision, covering its historical background, key technological tools, and various applications.</p>
                          <h3 id="keywords">Keywords</h3>
                          <p>Wearable devices, first person vision, egocentric vision, augmented reality, visual localization, action recognition, action anticipation, human-object interaction, procedural assistance</p>
                          <h3 id="aims-and-learning-objectives">Aims and learning objectives</h3>
                          <p align="justify">Participants will understand the advantages of first-person vision over third-person vision in analyzing behavior and building personalized applications. They will learn about: 1) differences between third-person and first-person vision, 2) devices for data collection and user services, and 3) algorithms for managing first-person visual data, object detection, human-object interaction, gaze understanding and visual-language relations.</p>
                          <div id="program"></div>
                          <h2 id="program">Program (Afternoon)</h2>
                          <h3 id="1415---1545">[TBA] Part I: History and motivations (Francesco Ragusa) <a href="">Slides</a></h3>
                          <ul>
                          <li>Agenda of the tutorial;</li>
                          <li>Definitions, motivations, history and research trends of First Person (egocentric) Vision;</li>
                          <li>Seminal works in First Person (Egocentric) Vision;</li>
                          <li>Differences between Third Person and First Person Vision;</li>
                          <li>First Person Vision datasets;</li>
                          <li>Wearable devices to acquire/process first person visual data;</li>
                          <li>Main research trends in First Person (Egocentric) Vision;</li>
                          </ul>
        
                          <h3 id="1715---1830">[TBA] Part II: Hand-Object Interactions in Egocentric Vision (Rosario Leonardi) <a href="">Slides</a></h3>
                          <ul>
                            <li>Introduction to Hand-Object Interactions Detection
                              <ul>
                                <li>Definition and importance of Hand-Object Interactions (HOI)</li>
                                <li>Applications in AR/VR, robotics, industrial monitoring, and assistive systems</li>
                              </ul>
                            </li>
                            <li>Datasets and Benchmarks for HOI in Egocentric Vision
                              <ul>
                                <li>Overview of popular datasets</li>
                                <li>Challenges in dataset collection and annotation</li>
                              </ul>
                            </li>
                            <li>Models and Architectures for Hand-Object Interactions Detection</li>
                          </ul>
                          
                          <h3 id="1715---1830">[TBA] Part III: Gaze Understanding and Visual-Language Benchmarks (Michele Mazzamuto) <a href="">Slides</a></h3>
                          <ul>
                            <ul>
                                <li>Gaze Signal Fundamentals
                                  <ul>
                                    <li>Definitions</li>
                                    <li>Gaze-Based Dataset</li>
                                    <li>Tasks</li>
                                  </ul>
                                </li>
                                <li>Gaze signal in computer vision
                                  <ul>
                                    <li>Gaze prediction</li>
                                    <li>The use of gaze information</li>
                                  </ul>
                                </li>
                                <li>Attended object detection</li>
                                <li>Gaze signal for mistake detection</li>
                                <li>Building procedural assistant with VLLM</li>
                                <li>Open Challenges and Future Directions</li>
                              </ul>                              
                          </ul>


                          <div id="reading"></div>
                          <h2 id="references---further-reading">References - Further Reading</h2>
                          <ul>
                          <li><a href="https://iplab.dmi.unict.it/live/">LIVE Group @ UNICT</a></li>
                          <li><a href="https://www.nextvisionlab.it">Next Vision</a></li>
                          </ul>
                          
                            </div>
                          
                            
                          
                          
                            
                          
                          
                            
                          </div>
                    </div>
                </div>
                <!-- About End -->



               
                
                
                <!-- Footer Start -->
                <div class="container-fluid bg-white pt-5 px-0">
                    <div class="container bg-dark text-light text-center py-5">
                        <div class="d-flex justify-content-center mb-4">
                            <a class="btn btn-outline-primary btn-square mr-2" href="#"><i class="fab fa-twitter"></i></a>
                            <a class="btn btn-outline-primary btn-square mr-2" href="#"><i class="fab fa-linkedin-in"></i></a>
                            
                        </div>
                        
                    </div>
                </div>
                <!-- Footer End -->
            </div>
        </div>
        
        <!-- Back to Top -->
        <a href="#" class="back-to-top"><i class="fa fa-angle-double-up"></i></a>
        
        <!-- JavaScript Libraries -->
        <script src="https://code.jquery.com/jquery-3.4.1.min.js"></script>
        <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.bundle.min.js"></script>
        <script src="lib/typed/typed.min.js"></script>
        <script src="lib/easing/easing.min.js"></script>
        <script src="lib/waypoints/waypoints.min.js"></script>
        <script src="lib/owlcarousel/owl.carousel.min.js"></script>
        <script src="lib/isotope/isotope.pkgd.min.js"></script>
        <script src="lib/lightbox/js/lightbox.min.js"></script>

        <!-- Contact Javascript File -->
        <script src="mail/jqBootstrapValidation.min.js"></script>
        <script src="mail/contact.js"></script>

        <!-- Template Javascript -->
        <script src="js/main.js"></script>
    </body>
</html>
